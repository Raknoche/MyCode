{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following: http://www.laurentluce.com/posts/twitter-sentiment-analysis-using-python-and-nltk/\n",
    "Could do something like https://marcobonzanini.com/2015/05/17/mining-twitter-data-with-python-part-6-sentiment-analysis-basics/ but unsupervised sentiment analysis typically doesn't work well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/richardknoche/anaconda/lib/python3.5/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "#Import the csv dataframe\n",
    "import pandas\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.util import *\n",
    "\n",
    "PoGo_labeled = pandas.read_csv('PoGo_Sentiment_Labeled_extended.csv')\n",
    "PoGo_labeled.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latt</th>\n",
       "      <th>location</th>\n",
       "      <th>long</th>\n",
       "      <th>multi-team</th>\n",
       "      <th>screenName</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>userId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Caldwell, ID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>desmond_ayala</td>\n",
       "      <td>pos</td>\n",
       "      <td>Which pokemon go team did y'all chose? #valor</td>\n",
       "      <td>2.953472e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-73.918741</td>\n",
       "      <td>Brooklyn, NY</td>\n",
       "      <td>40.694338</td>\n",
       "      <td>False</td>\n",
       "      <td>aphrospice</td>\n",
       "      <td>pos</td>\n",
       "      <td>#Magikarp practicing his struggle skills in th...</td>\n",
       "      <td>1.629086e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Bixby, OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>ABellgowan</td>\n",
       "      <td>pos</td>\n",
       "      <td>Pokemon Go is taking over my life #TeamInstinct</td>\n",
       "      <td>1.681036e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>JangoSnow</td>\n",
       "      <td>pos</td>\n",
       "      <td>Go Team Instinct! I like underdogs. :)  https:...</td>\n",
       "      <td>1.057434e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Niagara Falls, NY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>EmberLighta2</td>\n",
       "      <td>pos</td>\n",
       "      <td>#TeamMystic has total control of Niagara Falls!!</td>\n",
       "      <td>7.513920e+17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        latt           location       long multi-team     screenName  \\\n",
       "0        NaN       Caldwell, ID        NaN      False  desmond_ayala   \n",
       "1 -73.918741       Brooklyn, NY  40.694338      False     aphrospice   \n",
       "2        NaN          Bixby, OK        NaN      False     ABellgowan   \n",
       "3        NaN    Los Angeles, CA        NaN      False      JangoSnow   \n",
       "4        NaN  Niagara Falls, NY        NaN      False   EmberLighta2   \n",
       "\n",
       "  sentiment                                               text        userId  \n",
       "0       pos      Which pokemon go team did y'all chose? #valor  2.953472e+09  \n",
       "1       pos  #Magikarp practicing his struggle skills in th...  1.629086e+07  \n",
       "2       pos    Pokemon Go is taking over my life #TeamInstinct  1.681036e+09  \n",
       "3       pos  Go Team Instinct! I like underdogs. :)  https:...  1.057434e+07  \n",
       "4       pos   #TeamMystic has total control of Niagara Falls!!  7.513920e+17  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PoGo_labeled.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latt</th>\n",
       "      <th>location</th>\n",
       "      <th>long</th>\n",
       "      <th>multi-team</th>\n",
       "      <th>screenName</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>userId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Caldwell, ID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>desmond_ayala</td>\n",
       "      <td>pos</td>\n",
       "      <td>Which pokemon go team did y'all chose? #valor</td>\n",
       "      <td>2.953472e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-73.918741</td>\n",
       "      <td>Brooklyn, NY</td>\n",
       "      <td>40.694338</td>\n",
       "      <td>False</td>\n",
       "      <td>aphrospice</td>\n",
       "      <td>pos</td>\n",
       "      <td>#Magikarp practicing his struggle skills in th...</td>\n",
       "      <td>1.629086e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Bixby, OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>ABellgowan</td>\n",
       "      <td>pos</td>\n",
       "      <td>Pokemon Go is taking over my life #TeamInstinct</td>\n",
       "      <td>1.681036e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>JangoSnow</td>\n",
       "      <td>pos</td>\n",
       "      <td>Go Team Instinct! I like underdogs. :)  https:...</td>\n",
       "      <td>1.057434e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Niagara Falls, NY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>EmberLighta2</td>\n",
       "      <td>pos</td>\n",
       "      <td>#TeamMystic has total control of Niagara Falls!!</td>\n",
       "      <td>7.513920e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Alabama, USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>marshalljansen</td>\n",
       "      <td>pos</td>\n",
       "      <td>Stopped for lunch at a local seafood spot.  It...</td>\n",
       "      <td>1.359274e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Columbus, OH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>locustXreign</td>\n",
       "      <td>pos</td>\n",
       "      <td>Team valor straightedge fuck everyone else htt...</td>\n",
       "      <td>3.167318e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Lincroft, NJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>ThomasDalziel</td>\n",
       "      <td>pos</td>\n",
       "      <td>I know I'm not the first but I had to! It's to...</td>\n",
       "      <td>5.750384e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NYCcud</td>\n",
       "      <td>pos</td>\n",
       "      <td>Soooo mad I couldn't find this Blastoise on ca...</td>\n",
       "      <td>2.516288e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Virginia Beach, VA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>SarahFranchesca</td>\n",
       "      <td>pos</td>\n",
       "      <td>Any team instinct fellas wanna take some gyms ...</td>\n",
       "      <td>5.069618e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Iowa, USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>pay10bumgardner</td>\n",
       "      <td>pos</td>\n",
       "      <td>Team valor for life https://t.co/o4rSjKlK0X</td>\n",
       "      <td>2.186601e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Mount Juliet, TN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>Connor_Reap</td>\n",
       "      <td>pos</td>\n",
       "      <td>Just ordered mine. #TeamInstinct ‚ö°Ô∏è https://t....</td>\n",
       "      <td>1.243318e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Iowa, USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>s_cruves</td>\n",
       "      <td>pos</td>\n",
       "      <td>Out here in the Midwest flexin for Team Mystic...</td>\n",
       "      <td>3.799618e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Sheldon, TX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>igoldenglittr</td>\n",
       "      <td>pos</td>\n",
       "      <td>#TeamValor üòâüî•‚ú® https://t.co/AZl8VTnJN6</td>\n",
       "      <td>7.463782e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Crescent Springs, KY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>MikeSchutte</td>\n",
       "      <td>pos</td>\n",
       "      <td>@Bmeck12 @_chwitter_ team mystic rising up. #C...</td>\n",
       "      <td>2.999562e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Plano, TX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>AliAbbas_raza</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Team Valor is the Pokemon team equivalent of G...</td>\n",
       "      <td>1.423920e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Vancouver, WA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>Batmack81</td>\n",
       "      <td>pos</td>\n",
       "      <td>@rachelrickman_ #TeamValor</td>\n",
       "      <td>8.448853e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>zabrmc</td>\n",
       "      <td>neg</td>\n",
       "      <td>@kymcattys E. Yo system is tryin to purge that...</td>\n",
       "      <td>3.838762e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Depoe Bay, OR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>OmniKitten</td>\n",
       "      <td>pos</td>\n",
       "      <td>The squad needs this for our #PokemonGO huntin...</td>\n",
       "      <td>5.048522e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Florence-Graham, CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>jg5conde</td>\n",
       "      <td>pos</td>\n",
       "      <td>#TeamInstinct #LosAngeles https://t.co/cUKSDBW6Om</td>\n",
       "      <td>1.878952e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>McAllen, TX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>loudxclear</td>\n",
       "      <td>pos</td>\n",
       "      <td>@bbyzero and I are both team valor!!!!</td>\n",
       "      <td>5.255228e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Florida, USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>Ky_LeBraun</td>\n",
       "      <td>pos</td>\n",
       "      <td>#TeamInstinct https://t.co/s4ShQisxbG</td>\n",
       "      <td>1.598771e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Coldwater, NY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>glassj3n</td>\n",
       "      <td>pos</td>\n",
       "      <td>So are we getting matching shirts orrrr...? ht...</td>\n",
       "      <td>1.877503e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Tampa, FL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>Aleem2142</td>\n",
       "      <td>pos</td>\n",
       "      <td>TEAM MYSTIC LOLLLL I'M ABOUT IT https://t.co/H...</td>\n",
       "      <td>4.099156e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Waldorf, MD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>alexmyerly</td>\n",
       "      <td>neg</td>\n",
       "      <td>Team valor be so pressed üòÇ</td>\n",
       "      <td>2.375665e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Oklahoma, USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>Zekeee__</td>\n",
       "      <td>pos</td>\n",
       "      <td>I've decided to take my talents to Team Valor,...</td>\n",
       "      <td>2.753807e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-81.300600</td>\n",
       "      <td>DeLand, FL</td>\n",
       "      <td>29.022500</td>\n",
       "      <td>False</td>\n",
       "      <td>abbylove1994</td>\n",
       "      <td>pos</td>\n",
       "      <td>I officially chose a team #mystic #pokemongo @...</td>\n",
       "      <td>3.320379e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Ontario, CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>jpolicarpo143</td>\n",
       "      <td>pos</td>\n",
       "      <td>#TeamInstinct</td>\n",
       "      <td>9.770003e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Cary, NC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>GlamazonianRage</td>\n",
       "      <td>pos</td>\n",
       "      <td>Team instinct, bitches. #3dprinting #PokemonGO...</td>\n",
       "      <td>1.795242e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Kansas, USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>Versharky</td>\n",
       "      <td>neg</td>\n",
       "      <td>Or you're team mystic or whatever the fuck tha...</td>\n",
       "      <td>3.228229e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Virginia, USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>sugarlustx</td>\n",
       "      <td>pos</td>\n",
       "      <td>Catch of the day #PokemonGO #Geodude #Pokemon ...</td>\n",
       "      <td>2.063692e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         latt              location       long multi-team       screenName  \\\n",
       "0         NaN          Caldwell, ID        NaN      False    desmond_ayala   \n",
       "1  -73.918741          Brooklyn, NY  40.694338      False       aphrospice   \n",
       "2         NaN             Bixby, OK        NaN      False       ABellgowan   \n",
       "3         NaN       Los Angeles, CA        NaN      False        JangoSnow   \n",
       "4         NaN     Niagara Falls, NY        NaN      False     EmberLighta2   \n",
       "5         NaN          Alabama, USA        NaN      False   marshalljansen   \n",
       "6         NaN          Columbus, OH        NaN      False     locustXreign   \n",
       "7         NaN          Lincroft, NJ        NaN      False    ThomasDalziel   \n",
       "8         NaN           Atlanta, GA        NaN      False           NYCcud   \n",
       "9         NaN    Virginia Beach, VA        NaN      False  SarahFranchesca   \n",
       "10        NaN             Iowa, USA        NaN      False  pay10bumgardner   \n",
       "11        NaN      Mount Juliet, TN        NaN      False      Connor_Reap   \n",
       "12        NaN             Iowa, USA        NaN      False         s_cruves   \n",
       "13        NaN           Sheldon, TX        NaN      False    igoldenglittr   \n",
       "14        NaN  Crescent Springs, KY        NaN      False      MikeSchutte   \n",
       "15        NaN             Plano, TX        NaN      False    AliAbbas_raza   \n",
       "16        NaN         Vancouver, WA        NaN      False        Batmack81   \n",
       "17        NaN           Chicago, IL        NaN      False           zabrmc   \n",
       "18        NaN         Depoe Bay, OR        NaN      False       OmniKitten   \n",
       "19        NaN   Florence-Graham, CA        NaN      False         jg5conde   \n",
       "20        NaN           McAllen, TX        NaN      False       loudxclear   \n",
       "21        NaN          Florida, USA        NaN      False       Ky_LeBraun   \n",
       "22        NaN         Coldwater, NY        NaN      False         glassj3n   \n",
       "23        NaN             Tampa, FL        NaN      False        Aleem2142   \n",
       "24        NaN           Waldorf, MD        NaN      False       alexmyerly   \n",
       "25        NaN         Oklahoma, USA        NaN      False         Zekeee__   \n",
       "26 -81.300600            DeLand, FL  29.022500      False     abbylove1994   \n",
       "27        NaN           Ontario, CA        NaN      False    jpolicarpo143   \n",
       "28        NaN              Cary, NC        NaN      False  GlamazonianRage   \n",
       "29        NaN           Kansas, USA        NaN      False        Versharky   \n",
       "30        NaN         Virginia, USA        NaN      False       sugarlustx   \n",
       "\n",
       "   sentiment                                               text        userId  \n",
       "0        pos      Which pokemon go team did y'all chose? #valor  2.953472e+09  \n",
       "1        pos  #Magikarp practicing his struggle skills in th...  1.629086e+07  \n",
       "2        pos    Pokemon Go is taking over my life #TeamInstinct  1.681036e+09  \n",
       "3        pos  Go Team Instinct! I like underdogs. :)  https:...  1.057434e+07  \n",
       "4        pos   #TeamMystic has total control of Niagara Falls!!  7.513920e+17  \n",
       "5        pos  Stopped for lunch at a local seafood spot.  It...  1.359274e+08  \n",
       "6        pos  Team valor straightedge fuck everyone else htt...  3.167318e+07  \n",
       "7        pos  I know I'm not the first but I had to! It's to...  5.750384e+08  \n",
       "8        pos  Soooo mad I couldn't find this Blastoise on ca...  2.516288e+08  \n",
       "9        pos  Any team instinct fellas wanna take some gyms ...  5.069618e+07  \n",
       "10       pos        Team valor for life https://t.co/o4rSjKlK0X  2.186601e+09  \n",
       "11       pos  Just ordered mine. #TeamInstinct ‚ö°Ô∏è https://t....  1.243318e+08  \n",
       "12       pos  Out here in the Midwest flexin for Team Mystic...  3.799618e+08  \n",
       "13       pos             #TeamValor üòâüî•‚ú® https://t.co/AZl8VTnJN6  7.463782e+17  \n",
       "14       pos  @Bmeck12 @_chwitter_ team mystic rising up. #C...  2.999562e+08  \n",
       "15       NaN  Team Valor is the Pokemon team equivalent of G...  1.423920e+09  \n",
       "16       pos                         @rachelrickman_ #TeamValor  8.448853e+08  \n",
       "17       neg  @kymcattys E. Yo system is tryin to purge that...  3.838762e+07  \n",
       "18       pos  The squad needs this for our #PokemonGO huntin...  5.048522e+07  \n",
       "19       pos  #TeamInstinct #LosAngeles https://t.co/cUKSDBW6Om  1.878952e+07  \n",
       "20       pos             @bbyzero and I are both team valor!!!!  5.255228e+08  \n",
       "21       pos              #TeamInstinct https://t.co/s4ShQisxbG  1.598771e+08  \n",
       "22       pos  So are we getting matching shirts orrrr...? ht...  1.877503e+09  \n",
       "23       pos  TEAM MYSTIC LOLLLL I'M ABOUT IT https://t.co/H...  4.099156e+07  \n",
       "24       neg                         Team valor be so pressed üòÇ  2.375665e+08  \n",
       "25       pos  I've decided to take my talents to Team Valor,...  2.753807e+07  \n",
       "26       pos  I officially chose a team #mystic #pokemongo @...  3.320379e+09  \n",
       "27       pos                                      #TeamInstinct  9.770003e+08  \n",
       "28       pos  Team instinct, bitches. #3dprinting #PokemonGO...  1.795242e+08  \n",
       "29       neg  Or you're team mystic or whatever the fuck tha...  3.228229e+08  \n",
       "30       pos  Catch of the day #PokemonGO #Geodude #Pokemon ...  2.063692e+07  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PoGo_labeled.ix[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Training to identify positive/negative tweets (could also train to identified postive v non-positive (aka neg + nan))\n",
    "pos_tweets = [(PoGo_labeled.ix[row,'text'],'positive') for row in range(len(PoGo_labeled)) if PoGo_labeled.ix[row,'sentiment'] == 'pos']\n",
    "\n",
    "neg_tweets = [(PoGo_labeled.ix[row,'text'],'negative') for row in range(len(PoGo_labeled)) if PoGo_labeled.ix[row,'sentiment'] == 'neg']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Common words that don't help much\n",
    "from nltk.corpus import stopwords\n",
    "stopset = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "remove_words=['about','are','be','can','do','does','i','my','me','he','she','they','them','you','your','if','on','why','when','are']\n",
    "\n",
    "for word in remove_words:\n",
    "    if word in stopset:\n",
    "        stopset.remove(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use top feature list in classifier? (yes/no) : yes\n"
     ]
    }
   ],
   "source": [
    "#If we've made one, import top features list\n",
    "import pickle\n",
    "import os.path\n",
    "\n",
    "use_top_feature=False\n",
    "\n",
    "if os.path.isfile('top_features.txt'):\n",
    "    with open('top_features.txt', 'rb') as f:\n",
    "        use_top_feature_q=input('Use top feature list in classifier? (yes/no) : ')\n",
    "        if use_top_feature_q == 'yes':\n",
    "            use_top_feature=True\n",
    "        top_feature_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Using Bigrams\n",
    "#Combining pos + negative -- filtering out words with <3 letters (keeping things like RT)\n",
    "#need to run nltk.download() from command line and get stopwords corupus (freezes in the notebook)\n",
    "import string\n",
    "from random import shuffle\n",
    "from nltk.corpus import stopwords\n",
    "import itertools\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    " \n",
    "def stopword_filtered_word_feats(words):\n",
    "    return dict([(word, True) for word in words if word not in stopset])\n",
    " \n",
    "exclude = set(string.punctuation)\n",
    "excluded_words = ['teammystic','mystic','teamblue','blue',\\\n",
    "                  'teaminstinct','instinct','teamyellow','yellow',\\\n",
    "                  'teamvalor','valor','teamred','red']\n",
    "\n",
    "#consider removing team references\n",
    "def filter_tweets(tweets):\n",
    "    filtered_tweets = []\n",
    "    for (words, sentiment) in tweets: #equal number neg and pos tweets\n",
    "        words_filtered=[]\n",
    "        for word in words.split():\n",
    "            word = ''.join(ch for ch in word if ch not in exclude) #remove punctuation - improves CV performance a lot\n",
    "            if len(word) >= 1: #remove one letter words\n",
    "                #if word not in stopset: #remove common stop words\n",
    "                    if word[:4] == 'http': #treat URLs the same\n",
    "                        word='http'\n",
    "                    if word[0] == '#': #remove hashtags\n",
    "                        word=word[1:]\n",
    "                    if (word.lower() not in excluded_words): #remove team identifiers\n",
    "                        words_filtered.append(word.lower()) #require lower case\n",
    "\n",
    "        words_filtered = words_filtered #mark_negation(words_filtered)                               \n",
    "        \n",
    "        #Can search for bigrams with this\n",
    "        #bigram_finder = BigramCollocationFinder.from_words(words_filtered)\n",
    "        #bigrams = bigram_finder.nbest(BigramAssocMeasures.chi_sq, 200)   \n",
    "        \n",
    "        # if word not in stopset\n",
    "        if use_top_feature == True:\n",
    "            filtered_tweets.append(([word for word in words_filtered if word in top_feature_list],sentiment))\n",
    "        elif use_top_feature == False:\n",
    "            filtered_tweets.append(([word for word in words_filtered],sentiment))\n",
    "\n",
    "    return filtered_tweets\n",
    "\n",
    "filtered_pos_tweets = filter_tweets(pos_tweets)\n",
    "filtered_neg_tweets = filter_tweets(neg_tweets)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Divide into training and test datasets - give training set equal number of pos and neg by downsampling positives\n",
    "\n",
    "total_neg = len(neg_tweets)\n",
    "total_pos = len(pos_tweets)\n",
    "\n",
    "'''\n",
    "#Downsampling the positive tweets\n",
    "#half the negative tweets go in training\n",
    "len_train = int(round(len(filtered_neg_tweets)/2)*2)\n",
    "train_tweets = filtered_neg_tweets[:int(len_train/2)] + filtered_pos_tweets[:int(len_train/2)]\n",
    "\n",
    "#half of the remaining half go in cv\n",
    "cv_neg_cutoff = int( (len_train/2) + round((len(filtered_neg_tweets) - len_train/2)/2) )\n",
    "cv_pos_cutoff = int( (len_train/2) + round((len(filtered_pos_tweets) - len_train/2)/2) )\n",
    "cv_tweets =  filtered_neg_tweets[int(len_train/2):cv_neg_cutoff] +  filtered_pos_tweets[int(len_train/2):cv_pos_cutoff]  \n",
    "    \n",
    "#rest go into testing\n",
    "test_tweets =  filtered_neg_tweets[cv_neg_cutoff:] +  filtered_pos_tweets[cv_pos_cutoff:]  \n",
    "'''\n",
    "\n",
    "'''\n",
    "\n",
    "#Upsample negative tweets\n",
    "#half the negative tweets go in training\n",
    "neg_scale_factor = 3\n",
    "len_train = int(round(len(filtered_neg_tweets)/2)*2)\n",
    "train_tweets = filtered_neg_tweets[:int(len_train/2)]*neg_scale_factor + filtered_pos_tweets[:int(neg_scale_factor*len_train/2)]\n",
    "\n",
    "#half of the remaining half go in cv\n",
    "cv_neg_cutoff = int( (len_train/2) + round((len(filtered_neg_tweets) - len_train/2)/2) )\n",
    "cv_pos_cutoff = int( (neg_scale_factor*len_train/2) + round((len(filtered_pos_tweets) - neg_scale_factor*len_train/2)/2) )\n",
    "cv_tweets =  filtered_neg_tweets[int(len_train/2):cv_neg_cutoff] +  filtered_pos_tweets[int(neg_scale_factor*len_train/2):cv_pos_cutoff]  \n",
    "    \n",
    "#rest go into testing\n",
    "test_tweets =  filtered_neg_tweets[cv_neg_cutoff:] +  filtered_pos_tweets[cv_pos_cutoff:]  \n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "#True ratio of tweets\n",
    "#half the tweets go into training\n",
    "len_neg_train = int(round(len(filtered_neg_tweets)*0.5))\n",
    "len_pos_train = int(round(len(filtered_pos_tweets)*0.5))\n",
    "train_tweets = filtered_neg_tweets[:int(len_neg_train/2)] + filtered_pos_tweets[:int(len_pos_train/2)]\n",
    "\n",
    "#half of the remaining half go in cv\n",
    "cv_neg_cutoff = int( (len_neg_train/2) + round((len(filtered_neg_tweets) - len_neg_train/2)/2) )\n",
    "cv_pos_cutoff = int( (len_pos_train/2) + round((len(filtered_pos_tweets) - len_pos_train/2)/2) )\n",
    "cv_tweets =  filtered_neg_tweets[int(len_neg_train/2):cv_neg_cutoff] +  filtered_pos_tweets[int(len_pos_train/2):cv_pos_cutoff]  \n",
    "    \n",
    "#rest go into testing\n",
    "test_tweets =  filtered_neg_tweets[cv_neg_cutoff:] +  filtered_pos_tweets[cv_pos_cutoff:]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "928"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['team', 'be', 'so', 'üòÇ']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tweets[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import subjectivity\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment.util import *\n",
    "\n",
    "#Note: If train_tweets[0] was a list containing unigrams AND bigrams, we could extract the features like so:\n",
    "#all_feats = sentim_analyzer.unigram_word_feats(all_words_neg, min_freq=3)\n",
    "#bigram_feats = [ feat for feat in all_feats if type(feat) == tuple ]\n",
    "#unigram_feats = [ feat for feat in all_feats if type(feat) == str ]\n",
    "#The downside of the method above is you have to have the same top_n and min_freq for bigrams and unigrams\n",
    "\n",
    "#using stopwords makes pretty much no difference\n",
    "#best so far: 30,2 500,3: 66% improvement, 80% retention\n",
    "sentim_analyzer = SentimentAnalyzer()\n",
    "all_words = sentim_analyzer.all_words([doc for doc in train_tweets])\n",
    "bigram_feats = sentim_analyzer.bigram_collocation_feats([tweet[0] for tweet in train_tweets],top_n=30,min_freq=2)\n",
    "unigram_feats = sentim_analyzer.unigram_word_feats(all_words,top_n=300, min_freq=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentim_analyzer.add_feat_extractor(extract_unigram_feats, unigrams=unigram_feats)\n",
    "sentim_analyzer.add_feat_extractor(extract_bigram_feats, bigrams = bigram_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train_tweets must be a list of labeled tuples with tuples of the form (['word1','word2','word3'],'negative)\n",
    "#Must be a list even if the list only has one element!\n",
    "#The list does not need to have the bigrams labeled seperately, but it's okay if they are (they will just be ignored)\n",
    "#Having ONLY bigram tuples in the word list would not work, since they would all be ignored\n",
    "\n",
    "training_set = sentim_analyzer.apply_features(train_tweets)\n",
    "cv_set = sentim_analyzer.apply_features(cv_tweets)\n",
    "test_set = sentim_analyzer.apply_features(test_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier\n"
     ]
    }
   ],
   "source": [
    "trainer = NaiveBayesClassifier.train\n",
    "classifier = sentim_analyzer.train(trainer, training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating NaiveBayesClassifier results...\n"
     ]
    }
   ],
   "source": [
    "ev = sentim_analyzer.evaluate(cv_set)\n",
    "rec_pos = ev['Recall [positive]']\n",
    "rec_neg = ev['Recall [negative]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8922413793103449\n",
      "F-measure [negative]: 0.2574257425742574\n",
      "F-measure [positive]: 0.9419054996127033\n",
      "Precision [negative]: 0.29545454545454547\n",
      "Precision [positive]: 0.9325153374233128\n",
      "Recall [negative]: 0.22807017543859648\n",
      "Recall [positive]: 0.9514866979655712\n",
      "Contamination Improvement:  18.87119113573408\n"
     ]
    }
   ],
   "source": [
    "for key,value in sorted(ev.items()):            \n",
    "     print('{0}: {1}'.format(key, value))\n",
    "        \n",
    "print('Contamination Improvement: ', 100*(1-(1-rec_neg)/rec_pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want high negative recall so that we correctly identify and reject negative tweets often.  Ideally, we would have high negative precision as well.  In this case we have low negaive precision, which means we are identifying a lot of tweets as negative when they are not actually negative.  This is okay as long as it is randomly happening. \n",
    "However, if we accidentally identify a positive tweet as negative more often for a specific team, then we are skewing the results for that team. - Throw out any team identifiers in the tweets to solve this problem.\n",
    "\n",
    "Note: If we had high negative precision we could look at which teams are the most hated by looking at the fraction of negative tweets associated with each tam.  However, since we are randomly throwing tweets into the negative category every now and then, the distribution of hatred should be about 33% for each team -- VERIFY THIS IS THE CASE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Show the 20 most important features\n",
    "print (classifier.show_most_informative_features(150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_features=classifier.most_informative_features(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#removing contains() wrapping\n",
    "top_features=[top_features[row][0].split('contains(')[1][:-1] for row in range(len(top_features))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Splitting bigrams into unigrams\n",
    "cleaned_top_features = []\n",
    "for row in range(len(top_features)):\n",
    "    cleaned_top_features += top_features[row].split(' - ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "#Save the top features to text for itterative use\n",
    "\n",
    "if os.path.isfile('top_features.txt'):\n",
    "    os.remove('top_features.txt')\n",
    "with open('top_features.txt', 'wb') as f:\n",
    "    pickle.dump(cleaned_top_features, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#approximate error improvement\n",
    "num_states = 50\n",
    "scale_factor = 5 #scaling from number of labeled data to all data\n",
    "\n",
    "#old errors\n",
    "events_per_state = scale_factor*(total_pos+total_neg)/num_states\n",
    "orig_stat_err = (events_per_state) ** (1/2) / (events_per_state) #sqrt(n)/n gives rough fractional error\n",
    "orig_sys_err = total_neg/(total_neg+total_pos) \n",
    "orig_tot_err = (orig_stat_err ** 2 + orig_sys_err ** 2) ** (1/2)\n",
    "print ('Original - Stat: ', orig_stat_err, ' Sys: ', orig_sys_err, ' Total: ', orig_tot_err)\n",
    "\n",
    "#new errors\n",
    "events_per_state = scale_factor*(total_pos*rec_pos)/num_states\n",
    "new_stat_err = (events_per_state) ** (1/2) / (events_per_state) #sqrt(n)/n gives rough fractional error\n",
    "new_sys_err = (total_neg*(1-rec_neg))/(total_neg*(1-rec_neg)+total_pos*rec_pos) \n",
    "new_tot_err = (new_stat_err ** 2 + new_sys_err ** 2) ** (1/2)\n",
    "print ('Improved - Stat: ', new_stat_err, ' Sys: ', new_sys_err, ' Total: ', new_tot_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h1> After optimizing for CV set, get statistics for test set </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ev = sentim_analyzer.evaluate(test_set)\n",
    "rec_pos = ev['Recall [positive]']\n",
    "rec_neg = ev['Recall [negative]']\n",
    "\n",
    "for key,value in sorted(ev.items()):            \n",
    "     print('{0}: {1}'.format(key, value))\n",
    "        \n",
    "print('Contamination Improvement: ', 100*(1-(1-rec_neg)/rec_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
